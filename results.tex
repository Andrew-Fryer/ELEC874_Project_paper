\section{Results}\label{sec:results}

Talk about losses?
Here are the confusion matrices.
Here are some examples of images, pertebations, and resulting perturbed images.
I could also find the n closest signatures to a signature and see what that looks like...
Also try pertebations on swapped networks!
Also, try to perturb non-matching signatures and even random noise...

Here's a table of the accuracy (true/false positive/negative matix).
% todo: compute matrix...

Here's a genuine and a forge and we apply various epsilon values and also repeat...
    There are diminising returns on continually nudging a forge.

Here's how well we trick SigNet...

Here's the same thing with 2 genuines of different signatures.

Here's the same thing with 2 genuines of the same signature.


the training loss is not stable
the accuracy after \_ amount of training was 72% accuracy
It would take too long to get 100% accuracy

The validation loss was higher than the training loss even on the 1st epoch of training.
I believe this is because the images in the datapoints (image pairs with labels) have been seen before...


random noise can score well...

-------------------------------------------------

There are pure 0s in the forge, but not the original...
what if I add a bit of random noise to the forge?

I wonder if making the pixels boolean would help or hurt signet/advarsary...





WAT
    scaling the input to the net doesn't seem to change its output (latent) vector
    It that because it is doing some sort of normalization??
