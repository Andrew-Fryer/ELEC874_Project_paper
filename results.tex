\section{Results}\label{sec:results}

The main quantitative data can be seen in tables \ref{table:1} and \ref{table:2}.
These present a number of metrics for each model that was trained.
These are the number of true positives, false positives, false negatives, and true negatives, as well as accuracy (as computed in the SigNet paper\cite{sig_net}).
Additionally, the number of false positives and true negatives and the accuracy are computed and included after the forged image in each of the negative datapoints is perturbed as described is section \ref{my_fgsm}.
These metrics are shown for the 3 models (SigNet64, SigNet128, and SigNet256) which have dimensionality 64, 128, and 256 of their outputs (latent vectors).
All metrics are computed on the validation set.

\begin{table*}[t]
    \centering
    \begin{tabular}{|c | c >{\em}c | >{\em}c c | >{\bfseries}c | >{\em}c c >{\bfseries}c|}
        \hline
        \multirow{3}{*}{Dimensionality} & \multicolumn{5}{c|}{Normal} & \multicolumn{3}{c|}{Adversarial}\\
        \hline
        & \multicolumn{2}{c|}{Positive} & \multicolumn{2}{c|}{Negative} & \multirow{2}{*}{Accuracy} & Positive & Negative & \multirow{2}{*}{Accuracy}\\
        & True & False & False & True & & False & True & \\
        \hline
        64 & 1106 & 279 & 274 & 1101 & 79.96 & 43 & 1337 & 88.51\\
        128 & 1115 & 283 & 265 & 1097 & 80.14 & 0 & 1380 & 90.40\\
        256 & 1071 & 180 & 309 & 1200 & 82.28 & 0 & 1380 & 88.80\\
        \hline
    \end{tabular}
    \caption{Comparison of Accuracy using Latent Vector Sizes after 5 Epochs}
    \label{table:1}
\end{table*}

\begin{table*}[t]
    \centering
    \begin{tabular}{|c | c >{\em}c | >{\em}c c | >{\bfseries}c | >{\em}c c >{\bfseries}c|}
        \hline
        \multirow{3}{*}{Dimensionality} & \multicolumn{5}{c|}{Normal} & \multicolumn{3}{c|}{Adversarial}\\
        \hline
        & \multicolumn{2}{c|}{Positive} & \multicolumn{2}{c|}{Negative} & \multirow{2}{*}{Accuracy} & Positive & Negative & \multirow{2}{*}{Accuracy}\\
        & True & False & False & True & & False & True & \\
        \hline
        64 & 1347 & 0 & 33 & 1380 & 98.80 & 555 & 825 & 78.70\\
        128 & 1367 & 0 & 13 & 1380 & 99.53 & 1240 & 140 & 54.60\\
        256 & 1357 & 0 & 23 & 1380 & 99.17 & 938 & 442 & 65.18\\
        \hline
    \end{tabular}
    \caption{Comparison of Accuracy using Latent Vector Sizes after 20 epochs}
    \label{table:2}
\end{table*}

Table \ref{table:3} shows the same metrics when a threshold is chosen by analyzing the validation set (as described in the SigNet paper and section \ref{sec:threshold}).
Note that the threshold is not re-computed for the adversarial examples.
\begin{table*}[t]
    \centering
    \begin{tabular}{|c | c >{\em}c | >{\em}c c | >{\bfseries}c | >{\em}c c >{\bfseries}c|}
        \hline
        \multirow{3}{*}{Dimensionality} & \multicolumn{5}{c|}{Normal} & \multicolumn{3}{c|}{Adversarial}\\
        \hline
        & \multicolumn{2}{c|}{Positive} & \multicolumn{2}{c|}{Negative} & \multirow{2}{*}{Accuracy} & Positive & Negative & \multirow{2}{*}{Accuracy}\\
        & True & False & False & True & & False & True & \\
        \hline
        64 & 1380 & 23 & 0 & 1357 & 99.17 & 313 & 1067 & 88.66\\
        128 & 1380 & 9 & 0 & 1371 & 99.67 & 296 & 1084 & 89.28\\
        256 & 1380 & 5 & 0 & 1375 & 99.82 & 350 & 1030 & 87.32\\
        \hline
    \end{tabular}
    \caption{Comparison of Leaky Accuracy using Latent Vector Sizes after 20 epochs}
    \label{table:3}
\end{table*}

% If I need more content, I could graph the training loss and talk about how it stabilizes.

% the accuracy after \_ amount of training was 72% accuracy
% It would take too long to get 100% accuracy

% The validation loss was higher than the training loss even on the 1st epoch of training.
% I believe this is because the images in the datapoints (image pairs with labels) have been seen before...


% random noise can score well...
